\relax 
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plot of dataset $X$.\relax }}{2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nn_plot}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architecture for our simple neural network.\relax }}{2}\protected@file@percent }
\newlabel{fig:nn_arc}{{2}{2}}
\newlabel{eqn:1}{{1}{8}}
\newlabel{eqn:4}{{2}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  An example of a model $h : \mathcal  {X}=\{0,1,2,3\} \rightarrow [0,1]$. For calculating $T(x)$, we look at all data points with the same score $h(x)$, and compute the probability of $Y=1$ for these data points.\relax }}{9}\protected@file@percent }
\newlabel{tab:t-example}{{1}{9}}
\newlabel{eqn:mse-decomposiiton}{{7}{10}}
\newlabel{eqn:log-decompose}{{9}{10}}
\@writefile{toc}{\contentsline {paragraph}{Hint.}{10}\protected@file@percent }
